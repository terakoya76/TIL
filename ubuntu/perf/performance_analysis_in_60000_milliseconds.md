# Performance Analysis in 60,000ms

cf. http://techblog.netflix.com/2015/11/linux-performance-analysis-in-60s.html


## Summary
```bash
uptime
dmesg | tail
vmstat 1
mpstat -P ALL 1
pidstat 1
iostat -xz 1
free -m
sar -n DEV 1
sar -n TCP,ETCP 1
top
```


## 1. `uptime`

```bash
$ uptime
 23:51:26 up 21:31,  1 user,  load average: 30.02, 26.43, 19.02
```

これでリソースの負荷（あるいは要求具合）の高レベルな概要を知ることができる


## 2. `dmesg | tail`

```bash
$ dmesg | tail
[1880957.563150] perl invoked oom-killer: gfp_mask=0x280da, order=0, oom_score_adj=0
[...]
[1880957.563400] Out of memory: Kill process 18694 (perl) score 246 or sacrifice child
[1880957.563408] Killed process 18694 (perl) total-vm:1972392kB, anon-rss:1953348kB, file-rss:0kB
[2320864.954447] TCP: Possible SYN flooding on port 7001. Dropping request.  Check SNMP counters.
```

OOM, TCP Dropなどがシステムの異常が確認できる

## 3. `vmstat 1`

```bash
$ vmstat 1
procs ---------memory---------- ---swap-- -----io---- -system-- ------cpu-----
 r  b swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
34  0    0 200889792  73708 591828    0    0     0     5    6   10 96  1  3  0  0
32  0    0 200889920  73708 591860    0    0     0   592 13284 4282 98  1  1  0  0
32  0    0 200890112  73708 591860    0    0     0     0 9501 2154 99  1  0  0  0
32  0    0 200889568  73712 591856    0    0     0    48 11900 2459 99  0  0  0  0
32  0    0 200890208  73712 591860    0    0     0     0 15898 4840 98  1  1  0  0
^C
```

* `r`
  * CPUで実行中および順番を待っているプロセスの数。
  * これはI/Oを含んでいないので、CPUの飽和状態を見るのにロードアベレージよりも良いシグナルになります。
  * 言い換えると、`r` の値がCPU数よりも多ければ飽和状態ということです。
* `free`
  * キロバイトでの空きメモリ量。
  * 数えられないぐらいの桁数が表示されていたら十分なメモリがあります。
  * 7番目に出てくる `free -m` コマンドは、空きメモリのより詳しい説明を表示してくれます。
* `si, so`
  * スワップインとスワップアウト。
  * ゼロでない値があれば、メモリ不足。
* `us, sy, id, wa, st`
  * CPU時間の内訳で、すべてのCPUに対する平均値。
  * それぞれ、ユーザー時間、システム（カーネル）時間、アイドル時間、I/O待ち時間、stealされた時間（ほかのゲストマシンや、Xenの場合ゲストの分離されたドライバドメインによるsteal）。
  * user/system時間を足すことでCPUがビジーか確認できるでしょう。
    * I/O待ちが一定の数値を示しているならディスクがボトルネックです。
    * この時、タスクはディスクI/O待ちでブロックされてしまうため、CPUはアイドル状態になってしまっています。
  * システム時間は、I/O処理に必要です。20%を超えるような高いシステム時間は、詳しく調べる必要があると言える。

## 4. `mpstat -P ALL 1`

```bash
$ mpstat -P ALL 1
Linux 3.13.0-49-generic (titanclusters-xxxxx)  07/14/2015  _x86_64_ (32 CPU)

07:38:49 PM  CPU   %usr  %nice   %sys %iowait   %irq  %soft  %steal  %guest  %gnice  %idle
07:38:50 PM  all  98.47   0.00   0.75    0.00   0.00   0.00    0.00    0.00    0.00   0.78
07:38:50 PM    0  96.04   0.00   2.97    0.00   0.00   0.00    0.00    0.00    0.00   0.99
07:38:50 PM    1  97.00   0.00   1.00    0.00   0.00   0.00    0.00    0.00    0.00   2.00
07:38:50 PM    2  98.00   0.00   1.00    0.00   0.00   0.00    0.00    0.00    0.00   1.00
07:38:50 PM    3  96.97   0.00   0.00    0.00   0.00   0.00    0.00    0.00    0.00   3.03
[...]
```

CPU間のバランスの悪さを確認するために使える、CPUごとのCPU時間の内訳を表示します。
ひとつのCPUだけが忙しいのは、Single Threadアプリケーションが動いている証拠になり得ます。

## 5. `pidstat 1`

```bash
$ pidstat 1
Linux 3.13.0-49-generic (titanclusters-xxxxx)  07/14/2015    _x86_64_    (32 CPU)

07:41:02 PM   UID       PID    %usr %system  %guest    %CPU   CPU  Command
07:41:03 PM     0         9    0.00    0.94    0.00    0.94     1  rcuos/0
07:41:03 PM     0      4214    5.66    5.66    0.00   11.32    15  mesos-slave
07:41:03 PM     0      4354    0.94    0.94    0.00    1.89     8  java
07:41:03 PM     0      6521 1596.23    1.89    0.00 1598.11    27  java
07:41:03 PM     0      6564 1571.70    7.55    0.00 1579.25    28  java
07:41:03 PM 60004     60154    0.94    4.72    0.00    5.66     9  pidstat

07:41:03 PM   UID       PID    %usr %system  %guest    %CPU   CPU  Command
07:41:04 PM     0      4214    6.00    2.00    0.00    8.00    15  mesos-slave
07:41:04 PM     0      6521 1590.00    1.00    0.00 1591.00    27  java
07:41:04 PM     0      6564 1573.00   10.00    0.00 1583.00    28  java
07:41:04 PM   108      6718    1.00    0.00    0.00    1.00     0  snmp-pass
07:41:04 PM 60004     60154    1.00    4.00    0.00    5.00     9  pidstat
^C
```

`pidstat` は、`top` のプロセスごとの概要とも言えるものですが、スクリーンをクリアする代わりに連続して概要を表示します。
これは、時系列でのパターンを見るのに便利で、見たものを調査の記録にとっておく（コピー&ペースト）のにもよいでしょう。

上の例では、2つのjavaプロセスがCPUを消費している原因だとわかります。
`%CPU` 列は全CPUに対する使用率ですが、`1591%` という表示からjavaプロセスがほぼ16CPU分を使用していると分かります。

## 6. `iostat -xz 1`

```bash
$ iostat -xz 1
Linux 3.13.0-49-generic (titanclusters-xxxxx)  07/14/2015  _x86_64_ (32 CPU)

avg-cpu:  %user   %nice %system %iowait  %steal   %idle
          73.96    0.00    3.73    0.03    0.06   22.21

Device:   rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util
xvda        0.00     0.23    0.21    0.18     4.52     2.08    34.37     0.00    9.98   13.80    5.42   2.44   0.09
xvdb        0.01     0.00    1.02    8.94   127.97   598.53   145.79     0.00    0.43    1.78    0.28   0.25   0.25
xvdc        0.01     0.00    1.02    8.86   127.79   595.94   146.50     0.00    0.45    1.82    0.30   0.27   0.26
dm-0        0.00     0.00    0.69    2.32    10.47    31.69    28.01     0.01    3.23    0.71    3.98   0.13   0.04
dm-1        0.00     0.00    0.00    0.94     0.01     3.78     8.00     0.33  345.84    0.04  346.81   0.01   0.00
dm-2        0.00     0.00    0.09    0.07     1.35     0.36    22.50     0.00    2.55    0.23    5.62   1.78   0.03
[...]
^C
```

* `r/s, w/s, rkB/s, wkB/s`
  * デバイスに送られた秒間読み出し回数、書き込み回数、読み出しキロバイト、書き込みキロバイトを表します。
  * ワークロードの特徴をつかむのに使いましょう。パフォーマンスの問題はたいていの場合、単に過剰な負荷がかけられていることが原因です。
* `await`
  * I/Oの平均時間のミリ秒表示。これは、アプリケーションが待たされた時間で、キューに入っていた時間と実際のサービス時間の両方を含んでいます。
  * 期待した平均時間より長い場合、デバイスが飽和状態か、デバイス自体に問題がある可能性あり。
* `avgqu-sz`
  * デバイスに対して発行されたリクエストの平均数。
  *（複数のバックエンドディスクの前に立つ仮想デバイスは特に、デバイスはリクエストを通常は並行に処理しますが）1より大きい値は、飽和状態を表します。
* `%util`
  * デバイスの使用率。これは、実際にはビジーな割合で、デバイスが仕事をした時間を秒ごとに出したものです。
  * デバイスにもよりますが、一般的に60%より大きい値はパフォーマンスの劣化（`await` にも表れます）につながります。
  * 100％に近い値は通常、飽和状態を意味します。

ストレージデバイスがたくさんのバックエンドディスクを持つ論理ディスクデバイスの場合、使用率が100%ということは、何らかのI/Oが100%の時間処理され続けているということである一方で、バックエンドディスクは飽和状態からは程遠い可能性が高く、もっと多くの処理が可能なはずです。

注意したいのは、ディスクI/Oの低いパフォーマンスが、必ずしもアプリケーションの問題になるわけではないということです。
I/Oを非同期に実行するため、多くのテクニックがよく使われるので、アプリケーションはブロックされず、レイテンシも直接は影響してこないのです（例、読み出しには先読み、書き込みにはバッファリング）。


## 7. `free -m`

```bash
$ free -m
             total       used       free     shared    buffers     cached
Mem:        245998      24545     221453         83         59        541
-/+ buffers/cache:      23944     222053
Swap:            0          0          0
```

* `buffers`
  * ブロックデバイスのI/Oに使われるバッファキャッシュ
* `cached`
  * ファイルシステムによって使われるページキャッシュ

ディスクI/Oが高負荷になり（`iostat` で確認しましょう）パフォーマンスが悪化する可能性につながりかねないので、これらの値がゼロに近い値でないかを確認しておきたいところです。上の例では多くの容量がそれぞれありますので問題ないようです。

* `-/+ buffers/cache`
  * 使用中あるいは空きメモリを（`buffers`と`cached`を足し引きすることで）表す分かりやすい値を表示します。
  * Linuxは空きメモリをキャッシュに使用しますが、アプリケーションがメモリを要求したときにはすぐにそれを回収します。
  * 従って、`cached`なメモリは同じ行にある空きメモリの列の値に含まれているべきだということになります。


## 8. `sar -n DEV 1`

```bash
$ sar -n DEV 1
Linux 3.13.0-49-generic (titanclusters-xxxxx)  07/14/2015     _x86_64_    (32 CPU)

12:16:48 AM     IFACE   rxpck/s   txpck/s    rxkB/s    txkB/s   rxcmp/s   txcmp/s  rxmcst/s   %ifutil
12:16:49 AM      eth0  18763.00   5032.00  20686.42    478.30      0.00      0.00      0.00      0.00
12:16:49 AM        lo     14.00     14.00      1.36      1.36      0.00      0.00      0.00      0.00
12:16:49 AM   docker0      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00

12:16:49 AM     IFACE   rxpck/s   txpck/s    rxkB/s    txkB/s   rxcmp/s   txcmp/s  rxmcst/s   %ifutil
12:16:50 AM      eth0  19763.00   5101.00  21999.10    482.56      0.00      0.00      0.00      0.00
12:16:50 AM        lo     20.00     20.00      3.25      3.25      0.00      0.00      0.00      0.00
12:16:50 AM   docker0      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00
^C
```

ワークロードの目安になるネットワークインタフェースのスループットである `rxkB/s, txkB/s` を調べましょう。
また、何らかの制限に達していないかどうかも確認しましょう。
上の例では、eth0が22Mbytes/s、つまり176Mbits/secを受信しています（1Gbit/secの制限を十分下回っています）。

このバージョンでは、デバイスの使用率（全二重における上り下り両方での最大値）として `%ifutil` も表示されています。ただし、`nicstat` と同じく、なかなか正しい値を示してはくれず、上の例（0.00）のようにちゃんと動いていないように見える場合が多いようです。


## 9. `sar -n TCP,ETCP 1`

```bash
$ sar -n TCP,ETCP 1
Linux 3.13.0-49-generic (titanclusters-xxxxx)  07/14/2015    _x86_64_    (32 CPU)

12:17:19 AM  active/s passive/s    iseg/s    oseg/s
12:17:20 AM      1.00      0.00  10233.00  18846.00

12:17:19 AM  atmptf/s  estres/s retrans/s isegerr/s   orsts/s
12:17:20 AM      0.00      0.00      0.00      0.00      0.00

12:17:20 AM  active/s passive/s    iseg/s    oseg/s
12:17:21 AM      1.00      0.00   8359.00   6039.00

12:17:20 AM  atmptf/s  estres/s retrans/s isegerr/s   orsts/s
12:17:21 AM      0.00      0.00      0.00      0.00      0.00
^C
```

* `active/s`
  * 1秒あたりのローカルから接続を開始したTCPコネクション数（例、`connect()` による接続）
* `passive/s`
  * 1秒あたりのリモートから接続を開始したTCPコネクション数（例、`accept()` による接続）
* `retrans/s`
  * 1秒あたりのTCP再送数
* `active/s, passive/s`
  * それぞれ新しく受け入れたコネクション数と新しく下流に向けて張ったコネクション数で、サーバの負荷を大まかに把握するのに便利です。
  * activeを外向き、passiveを内向きと考えるのに便利ですが、厳密に正しいとは言えません（ローカルホストからローカルホストへのコネクションなどを考慮する必要があるなど）。

再送はネットワークあるいはサーバの問題のサインです。
ネットワークの信頼性が低い（例、パブリックなインターネット）か、サーバが過負荷でパケットをドロップしているかでしょう。
上の例では、1秒に1 TCPコネクションしか生成されていません。


## 10. `top`

```bash
$ top
top - 00:15:40 up 21:56,  1 user,  load average: 31.09, 29.87, 29.92
Tasks: 871 total,   1 running, 868 sleeping,   0 stopped,   2 zombie
%Cpu(s): 96.8 us,  0.4 sy,  0.0 ni,  2.7 id,  0.1 wa,  0.0 hi,  0.0 si,  0.0 st
KiB Mem:  25190241+total, 24921688 used, 22698073+free,    60448 buffers
KiB Swap:        0 total,        0 used,        0 free.   554208 cached Mem

   PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND
 20248 root      20   0  0.227t 0.012t  18748 S  3090  5.2  29812:58 java
  4213 root      20   0 2722544  64640  44232 S  23.5  0.0 233:35.37 mesos-slave
 66128 titancl+  20   0   24344   2332   1172 R   1.0  0.0   0:00.07 top
  5235 root      20   0 38.227g 547004  49996 S   0.7  0.2   2:02.74 java
  4299 root      20   0 20.015g 2.682g  16836 S   0.3  1.1  33:14.42 java
     1 root      20   0   33620   2920   1496 S   0.0  0.0   0:03.82 init
     2 root      20   0       0      0      0 S   0.0  0.0   0:00.02 kthreadd
     3 root      20   0       0      0      0 S   0.0  0.0   0:05.35 ksoftirqd/0
     5 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 kworker/0:0H
     6 root      20   0       0      0      0 S   0.0  0.0   0:06.94 kworker/u256:0
     8 root      20   0       0      0      0 S   0.0  0.0   2:38.05 rcu_sched
```

topコマンドには、これより前に見てきたメトリクスの多くが含まれています。
負荷が変わりやすいことを示してくれるここまで見てきたコマンドと違って、ざっくりと確認したいときには便利でしょう。
